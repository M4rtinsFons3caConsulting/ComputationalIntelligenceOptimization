{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The story**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "\n",
    "from rubix.run import run, run_grid\n",
    "from rubix.constants import DATA_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(\n",
    "#     path_: str\n",
    "# ) -> None:\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Executes the optimization routine.\n",
    "\n",
    "#     This function prepares the input data, initializes the solver, and executes\n",
    "#     the optimization process. It accepts arbitrary keyword arguments, which may\n",
    "#     include optional parameters for the solver or runtime configuration.\n",
    "\n",
    "#     Expected kwargs:\n",
    "#         path (str): Optional path to the input dataset. Defaults to DATA_V1.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     config_path = f\"../rubix.configs/{path_}\"\n",
    "\n",
    "#     # Load the data from the provided path\n",
    "#     dataset = load_data(\n",
    "#         path=DATA_V1,\n",
    "#         config_path = config_path\n",
    "#     )\n",
    "\n",
    "#     # Process the data to the necessary shape\n",
    "#     dataset = process_data(dataset)\n",
    "    \n",
    "#     print(dataset)\n",
    "    \n",
    "#     # Initialize the solver\n",
    "#     solver = Solver(\n",
    "#         dataset.matrix, \n",
    "#         dataset.cost_params,  \n",
    "#         dataset.layout_params, \n",
    "#         dataset.solver_params\n",
    "#     )\n",
    "\n",
    "#     # Solve the problem\n",
    "#     result = solver.solve()\n",
    "\n",
    "#     return dataset, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 50\n",
    "# Will save the fitness of the best individual in the end of each of the 30 runs\n",
    "rand_best_fitnesses = []\n",
    "hc_best_fitnesses = []\n",
    "sa_best_fitnesses = []\n",
    "ga_best_fitnesses = []\n",
    "rs_best_fitnesses = []\n",
    "\n",
    "for run_nr in range(3):\n",
    "    # Random Search\n",
    "    dataset, result, history = run(\n",
    "        data_path=DATA_V1\n",
    "        ,config_file='random_search_config.json'\n",
    "    )\n",
    "    rand_best_fitnesses.append(result.rubix_fitness.item())\n",
    "\n",
    "    # Hill Climbing\n",
    "    dataset, result, history = run(\n",
    "        data_path=DATA_V1\n",
    "        ,config_file='hill_climber_config.json'\n",
    "    )\n",
    "    hc_best_fitnesses.append(result.rubix_fitness.item())\n",
    "\n",
    "    # Annealer\n",
    "    dataset, result, history = run(\n",
    "        data_path=DATA_V1\n",
    "        ,config_file='annealing_config.json'\n",
    "    )\n",
    "    sa_best_fitnesses.append(result.rubix_fitness.item())\n",
    "\n",
    "    # Genetic\n",
    "    dataset, result, history = run(\n",
    "        data_path=DATA_V1\n",
    "        ,config_file='genetic_config.json'\n",
    "    )\n",
    "    ga_best_fitnesses.append(result.rubix_fitness.item())\n",
    "\n",
    "    # Rubix Search\n",
    "    dataset, result, history = run(\n",
    "        data_path=DATA_V1\n",
    "        ,config_file='rubix_search_config.json'\n",
    "    )\n",
    "    rs_best_fitnesses.append(result.rubix_fitness.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame in long format\n",
    "df = pd.DataFrame({\n",
    "    'value': rand_best_fitnesses + hc_best_fitnesses + sa_best_fitnesses + ga_best_fitnesses + rs_best_fitnesses,\n",
    "    'group':   \n",
    "        ['Random Search'] * len(rand_best_fitnesses) + \n",
    "        ['Hill Climber'] * len(hc_best_fitnesses) + \n",
    "        ['Annealing'] * len(sa_best_fitnesses) + \n",
    "        ['Genetic'] * len(ga_best_fitnesses) +\n",
    "        ['Rubix Search'] * len(rs_best_fitnesses)\n",
    "})\n",
    "\n",
    "# Set a beautiful theme\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"pastel\", font_scale=1.2)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.boxplot(x='group', y='value', data=df, width=0.5, linewidth=2.5, fliersize=4)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Fitness Comparison for Optimization Algorithms', fontsize=16)\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Fitness of best found individual')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet(\n",
      "  stage: Processed,\n",
      "\n",
      "  dataframe:\n",
      "              Name Position  Skill  Salary (â‚¬M)\n",
      "0      Alex Carter       GK     85             90\n",
      "1     Jordan Smith       GK     88            100\n",
      "2    Ryan Mitchell       GK     83             85\n",
      "3   Chris Thompson       GK     80             80\n",
      "4  Blake Henderson       GK     87             95\n",
      "\n",
      "  constructors:\n",
      "    label_col: 'Position'\n",
      "    weights: ['Skill', 'Salary (â‚¬M)']\n",
      "    constraints: {'GK': 1, 'DEF': 2, 'MID': 2, 'FWD': 2}\n",
      "    window: []\n",
      "\n",
      "  solver parameters:\n",
      "    strategy: 'genetic'\n",
      "    n: 100\n",
      "    n_pairs: 50\n",
      "    epochs: 200\n",
      "    patience: 50\n",
      "    select_type: 'tournament'\n",
      "    vs_type: 'probabilistic'\n",
      "    x_strategy: 'slice_crossover'\n",
      "    vs_size: 2\n",
      "    elitism: 1\n",
      "    p_cross: 0.8\n",
      "    p_mutation: 0.1\n",
      "    p_roll: 0.5\n",
      "    p_swap: 0.5\n",
      "\n",
      "  matrix:\n",
      "tensor([[ 0,  5, 10, 15, 20, 25, 30],\n",
      "        [ 1,  6, 11, 16, 21, 26, 31],\n",
      "        [ 2,  7, 12, 17, 22, 27, 32],\n",
      "        [ 3,  8, 13, 18, 23, 28, 33],\n",
      "        [ 4,  9, 14, 19, 24, 29, 34]])\n",
      "\n",
      "  layout parameters:\n",
      "    block_indices: [0, 1, 3, 5]\n",
      "    block_ranges: [(0, 1), (1, 3), (3, 5), (5, 7)]\n",
      "    n_cols: 5\n",
      "    n_rows: 7\n",
      "    n_layers: 100\n",
      "    window: (5, 7)\n",
      "    rubix_shape: (100, 5, 7)\n",
      "\n",
      "  cost parameters:\n",
      "    arrays:\n",
      "       0: tensor([85., 88., 83., 80., 87., 81., 79.], dtype=torch.float64) ...\n",
      "       1: tensor([ 90., 100.,  85.,  80.,  95.,  72.,  65.], dtype=torch.float64) ...\n",
      "    lookup:\n",
      "      0: 'Skill'\n",
      "      1: 'Salary (â‚¬M)'\n",
      "\n",
      ")\n",
      "\n",
      "Running for 200 iterations.\n",
      "Epoch 1/200...\n",
      "Epoch 2/200...\n",
      "Epoch 3/200...\n",
      "Epoch 4/200...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'genetic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Run for 30 times\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run_nr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m30\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     _, _, fitness_over_gens = \u001b[43mrun_grid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_V1\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenetic_config.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43mdynamic_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrossover_cfg\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43melitism\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     config_results.append(fitness_over_gens)\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# df.loc[run_nr] = fitness_over_gens\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IMS/2024 - 2025/Projects/ComputationalIntelligenceOptimization/rubix/run.py:99\u001b[39m, in \u001b[36mrun_grid\u001b[39m\u001b[34m(data_path, config_file, dynamic_params)\u001b[39m\n\u001b[32m     96\u001b[39m     json.dump(config, tmp)\n\u001b[32m     97\u001b[39m     tmp_path = os.path.basename(tmp.name)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m dataset, result, history = \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m os.remove(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtmp_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataset, result, history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IMS/2024 - 2025/Projects/ComputationalIntelligenceOptimization/rubix/run.py:74\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(data_path, config_file)\u001b[39m\n\u001b[32m     66\u001b[39m solver = Solver(\n\u001b[32m     67\u001b[39m     dataset.matrix, \n\u001b[32m     68\u001b[39m     dataset.cost_params,  \n\u001b[32m     69\u001b[39m     dataset.layout_params, \n\u001b[32m     70\u001b[39m     dataset.solver_params\n\u001b[32m     71\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Solve the problem\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m result, history = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dataset, result, history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IMS/2024 - 2025/Projects/ComputationalIntelligenceOptimization/rubix/classes/solver.py:62\u001b[39m, in \u001b[36mSolver.solve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03mExecutes the optimization process using the selected solver strategy.\u001b[39;00m\n\u001b[32m     50\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m    Rubix: The Rubix instance representing the best solution found by the strategy.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     60\u001b[39m strategy_fn = STRATEGY[\u001b[38;5;28mself\u001b[39m.solver_params[\u001b[33m\"\u001b[39m\u001b[33mstrategy\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m solution, solution_history = \u001b[43mstrategy_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mRubix\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msolver_params\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Parse history to list\u001b[39;00m\n\u001b[32m     68\u001b[39m solution_history = torch.stack(solution_history).numpy().tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IMS/2024 - 2025/Projects/ComputationalIntelligenceOptimization/rubix/functions/solver_strategies.py:202\u001b[39m, in \u001b[36mgenetic_evolver\u001b[39m\u001b[34m(cube, params)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# Apply mutation\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.rand(\u001b[32m1\u001b[39m).item() < prob_mutation:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     new_cube = \u001b[43mapply_operator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_slices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     new_cube = Rubix(new_slices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IMS/2024 - 2025/Projects/ComputationalIntelligenceOptimization/rubix/functions/operators.py:334\u001b[39m, in \u001b[36mapply_operator\u001b[39m\u001b[34m(cube, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mblock_ranges\u001b[39m\u001b[33m'\u001b[39m] = Rubix.block_ranges\n\u001b[32m    332\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mvalid_swaps\u001b[39m\u001b[33m'\u001b[39m] = Rubix.valid_swaps\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m operator, mapping_fn = \u001b[43mOPERATOR_STRATEGIES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrategy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mapping_fn:\n\u001b[32m    337\u001b[39m     mapping = mapping_fn(**kwargs)\n",
      "\u001b[31mKeyError\u001b[39m: 'genetic'"
     ]
    }
   ],
   "source": [
    "POP_SIZE = 100\n",
    "GENERATIONS = 200\n",
    "\n",
    "grid_params = {\n",
    "    \"crossover\": [{\n",
    "            \"x_strategy\": \"slice_crossover\",\n",
    "            \"p_cross\": 0.8\n",
    "        }\n",
    "        # , {\n",
    "        #     \"x_strategy\": \"cube_crossover\",\n",
    "        #     \"xo_prob\": 0.8\n",
    "        # }\n",
    "    ],\n",
    "    # \"mutation\": [{\n",
    "    #         \"function\": swap_mutation,\n",
    "    #         \"mut_prob\": 0.8\n",
    "    #     },\n",
    "    #     {\n",
    "    #         \"function\": inversion_mutation,\n",
    "    #         \"mut_prob\": 0.2\n",
    "    #     }\n",
    "    # ],\n",
    "    \"elitism\": [{\n",
    "        \"elitism\": 1\n",
    "    }, {\n",
    "        \"elitism\": 0\n",
    "    }]\n",
    "}\n",
    "\n",
    "fitness_dfs = {}\n",
    "\n",
    "# Generate all combinations of the grid parameters\n",
    "grid = list(\n",
    "    itertools.product(\n",
    "        grid_params[\"crossover\"]\n",
    "        # ,grid_params[\"mutation\"]\n",
    "        ,grid_params[\"elitism\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "for crossover_cfg, elitism in grid:\n",
    "    # Create empty dataframe for each configuration\n",
    "    # Columns have the fitness in each generation, rows will have results for each run\n",
    "    df = pd.DataFrame(columns=range(GENERATIONS))  # Shape will be max(run_nr) + 1 x GENERATIONS\n",
    "\n",
    "    config_results = []\n",
    "\n",
    "    # Run for 30 times\n",
    "    for run_nr in range(30):\n",
    "        _, _, fitness_over_gens = run_grid(\n",
    "            data_path=DATA_V1\n",
    "            ,config_file='genetic_config.json'\n",
    "            ,dynamic_params=crossover_cfg | elitism\n",
    "        )\n",
    "        config_results.append(fitness_over_gens)\n",
    "\n",
    "        # df.loc[run_nr] = fitness_over_gens\n",
    "\n",
    "        padded_fitness = fitness_over_gens + [float('inf')] * (GENERATIONS - len(fitness_over_gens))\n",
    "\n",
    "        # Now assign\n",
    "        df.loc[run_nr] = padded_fitness\n",
    "\n",
    "    # Create a label for the configuration\n",
    "    config_label = (\n",
    "        f\"{crossover_cfg[\"x_strategy\"]}{crossover_cfg[\"p_cross\"]}_\"\n",
    "        f\"mutation_configs_missing_elitism={elitism[\"elitism\"]}\"\n",
    "    )\n",
    "\n",
    "    # Save configuration results in the dictionary\n",
    "    fitness_dfs[config_label] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fitness_over_gen(fitness_dfs: dict[str, pd.DataFrame]):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "    handles, labels = [], []\n",
    "\n",
    "    for config_name, df in fitness_dfs.items():\n",
    "        mean_fitness = df.mean(axis=0)\n",
    "        median_fitness = df.median(axis=0)\n",
    "        \n",
    "        line1, = axes[0].plot(mean_fitness.index, mean_fitness.values, label=config_name)\n",
    "        axes[1].plot(median_fitness.index, median_fitness.values, label=config_name)\n",
    "\n",
    "        handles.append(line1)\n",
    "        labels.append(config_name)\n",
    "\n",
    "    axes[0].set_title(\"Mean Fitness Across Generations\")\n",
    "    axes[1].set_title(\"Median Fitness Across Generations\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Generation\")\n",
    "        ax.set_ylabel(\"Fitness\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Shared boxed legend below\n",
    "    legend = fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='lower center',\n",
    "        bbox_to_anchor=(0.5, -0.15),\n",
    "        ncol=2,\n",
    "        frameon=True,\n",
    "        borderpad=1\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fitness_over_gen(fitness_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
